{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "515b7545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from tqdm import notebook\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout, Add, dot, LSTM\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5694825e",
   "metadata": {},
   "source": [
    "https://github.com/google-research/bert\n",
    "\n",
    "https://huggingface.co/transformers/model_doc/bert.html#bertmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6188d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# считываем датасеты с нормированными описаниями тендеров\n",
    "\n",
    "train_data_desc_stemmed = pd.read_csv('../data/intermid/train_data_desc_stemmed.csv')\n",
    "test_data_desc_stemmed = pd.read_csv('../data/intermid/test_data_desc_stemmed.csv')\n",
    "\n",
    "# соединяем датасеты\n",
    "\n",
    "data = pd.concat([train_data_desc_stemmed, test_data_desc_stemmed], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66e6bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c162adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# инициализация модели\n",
    "tokenizer = transformers.BertTokenizer(vocab_file='../download_models/uncased_L-12_H-768_A-12/vocab.txt')\n",
    "config = transformers.BertConfig.from_json_file('../download_models/uncased_L-12_H-768_A-12/bert_config.json')\n",
    "model = transformers.BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c90170a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized head: 0    [101, 1198, 29747, 29436, 29748, 29741, 10260,...\n",
      "1    [101, 1194, 16856, 10325, 14150, 29740, 16856,...\n",
      "2    [101, 1194, 16856, 10325, 14150, 29740, 16856,...\n",
      "3    [101, 1194, 16856, 14150, 29742, 29436, 15290,...\n",
      "4    [101, 1194, 16856, 10325, 14150, 29740, 16856,...\n",
      "Name: text_description_tender_stemmed, dtype: object\n",
      "Attention mask: (1000, 500)\n"
     ]
    }
   ],
   "source": [
    "tokenized = data['text_description_tender_stemmed'].apply(lambda x: tokenizer.encode(x, max_length=500, add_special_tokens = True))\n",
    "print(\"Tokenized head:\", tokenized.head())\n",
    "n = max(map(len, tokenized))  # применим padding (уравняем длины исходных описаний)\n",
    "for i in range(len(tokenized)):   \n",
    "    tokenized[i] = tokenized[i] + [0]*(n-len(tokenized[i]))\n",
    "tokenized = np.stack(tokenized)\n",
    "attention_mask = np.where(tokenized != 0, 1, 0) # создадим маску (укажем нулевые и ненулевые значения)\n",
    "print(\"Attention mask:\", attention_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78ec32b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2905bafbd41346b8afd772a4ef0aa362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# сделаем цикл по батчам:\n",
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(tokenized.shape[0] // batch_size)):       \n",
    "    batch = torch.LongTensor(tokenized[batch_size*i:batch_size*(i+1)])  # преобразуем данные в формат тензоров\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])  # преобразуем маску\n",
    "    with torch.no_grad(): # градиенты не нужны, модель BERT обучать не будем\n",
    "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        # получаем эмбеддинги для батча, передав модели данные и маску\n",
    "    embeddings.append(batch_embeddings[0][:,0,:].numpy())  \n",
    "        # извлекаем нужные элементы из тензора и добавляем в список эмбеддингов  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "064cc69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.4706191 ,  0.12665111, -0.13658667, ..., -0.11170372,\n",
       "          0.3024224 ,  0.3312525 ],\n",
       "        [-0.23084061,  0.34706017,  0.09129888, ..., -0.02850064,\n",
       "          0.5029464 ,  0.2785562 ],\n",
       "        [-0.37292403,  0.20395312, -0.11883457, ..., -0.03590769,\n",
       "          0.41513634,  0.3958849 ],\n",
       "        ...,\n",
       "        [-0.3669382 ,  0.32654774,  0.00282824, ..., -0.02264736,\n",
       "          0.45594034,  0.30381262],\n",
       "        [-0.31806135,  0.2796135 ,  0.00537187, ..., -0.05984727,\n",
       "          0.39598483,  0.31441912],\n",
       "        [-0.5517641 ,  0.19259205, -0.31420934, ..., -0.02630982,\n",
       "          0.5279942 ,  0.36230895]], dtype=float32),\n",
       " array([[-0.26976913,  0.33320117, -0.04327675, ...,  0.00703785,\n",
       "          0.47228822,  0.24412946],\n",
       "        [-0.29748487,  0.3178135 ,  0.03755035, ..., -0.13640223,\n",
       "          0.33707598,  0.32772842],\n",
       "        [-0.19031663,  0.3059399 ,  0.03691196, ...,  0.04728355,\n",
       "          0.4600698 ,  0.21634683],\n",
       "        ...,\n",
       "        [-0.2665012 ,  0.4299869 , -0.00155119, ..., -0.11910931,\n",
       "          0.36997822,  0.29639906],\n",
       "        [-0.25890958,  0.44239432, -0.02514566, ..., -0.07371339,\n",
       "          0.54768324,  0.32867703],\n",
       "        [-0.23316011,  0.28195977,  0.02844758, ..., -0.10706485,\n",
       "          0.43792963,  0.17474815]], dtype=float32),\n",
       " array([[-4.0398243e-01,  3.2810557e-01,  6.2899396e-02, ...,\n",
       "          4.9465701e-02,  4.2434004e-01,  3.9732221e-01],\n",
       "        [-1.8524686e-01,  3.7108904e-01, -1.9221772e-02, ...,\n",
       "         -1.0915782e-01,  4.1253614e-01,  3.1067401e-01],\n",
       "        [-4.4190755e-01,  1.6871879e-01, -1.0867882e-01, ...,\n",
       "         -6.9565088e-02,  4.4586265e-01,  3.8870502e-01],\n",
       "        ...,\n",
       "        [-8.8090710e-02,  3.1220517e-01,  1.3014812e-02, ...,\n",
       "         -1.2186765e-01,  6.0938370e-01,  1.8016973e-01],\n",
       "        [-1.4349987e-01,  4.3122032e-01,  7.7065863e-03, ...,\n",
       "         -1.1297076e-01,  5.8520305e-01,  1.6453831e-01],\n",
       "        [-1.5397401e-01,  3.7468162e-01, -3.4699962e-04, ...,\n",
       "         -1.0701711e-01,  6.8175685e-01,  1.3345183e-01]], dtype=float32),\n",
       " array([[-0.33009738,  0.3394519 ,  0.07919173, ..., -0.02620062,\n",
       "          0.33158714,  0.4446164 ],\n",
       "        [-0.13038334,  0.34070313,  0.04597898, ..., -0.07133772,\n",
       "          0.57159877,  0.22469886],\n",
       "        [-0.08858528,  0.33958057,  0.0611733 , ..., -0.18934307,\n",
       "          0.5339706 ,  0.3244275 ],\n",
       "        ...,\n",
       "        [-0.37764814,  0.35061744, -0.01152892, ..., -0.04638223,\n",
       "          0.42413685,  0.24595512],\n",
       "        [-0.35025603,  0.23676166, -0.09685333, ..., -0.01572664,\n",
       "          0.4458148 ,  0.3738498 ],\n",
       "        [-0.28607905,  0.42861927, -0.02239538, ..., -0.1165966 ,\n",
       "          0.25754195,  0.31474632]], dtype=float32),\n",
       " array([[-0.50740546,  0.18292168, -0.05633484, ..., -0.07682036,\n",
       "          0.5689317 ,  0.5369675 ],\n",
       "        [-0.22021174,  0.29525355, -0.01072654, ..., -0.08637115,\n",
       "          0.46740633,  0.2714286 ],\n",
       "        [-0.3695213 ,  0.36038882, -0.00978594, ..., -0.03441858,\n",
       "          0.4205504 ,  0.23170686],\n",
       "        ...,\n",
       "        [-0.10430749,  0.24234426,  0.0236696 , ..., -0.01487698,\n",
       "          0.5494262 ,  0.18419383],\n",
       "        [-0.18534872,  0.31701386, -0.07515173, ..., -0.01657703,\n",
       "          0.6051496 ,  0.14955959],\n",
       "        [-0.46997344,  0.1798518 , -0.10642053, ..., -0.09090436,\n",
       "          0.50326574,  0.42150152]], dtype=float32),\n",
       " array([[-0.40447083,  0.12446707, -0.19171704, ..., -0.01626601,\n",
       "          0.37717217,  0.3848276 ],\n",
       "        [-0.18883397,  0.37455258,  0.03930403, ..., -0.04238561,\n",
       "          0.47042623,  0.26436827],\n",
       "        [-0.11067735,  0.29514882,  0.05177059, ..., -0.02894789,\n",
       "          0.5001106 ,  0.21893276],\n",
       "        ...,\n",
       "        [-0.24279451,  0.26301968,  0.05047486, ..., -0.05116312,\n",
       "          0.3438231 ,  0.1802275 ],\n",
       "        [-0.13991295,  0.33117563,  0.03591397, ..., -0.12188149,\n",
       "          0.4990911 ,  0.1995795 ],\n",
       "        [-0.5423896 ,  0.12538981, -0.349818  , ..., -0.15430869,\n",
       "          0.30233923,  0.42692944]], dtype=float32),\n",
       " array([[-0.30421892,  0.22156689, -0.06615923, ..., -0.11706058,\n",
       "          0.5389929 ,  0.29456508],\n",
       "        [-0.38801777,  0.30917075, -0.12040851, ...,  0.08878186,\n",
       "          0.39522454,  0.35095274],\n",
       "        [-0.20849948,  0.3193803 ,  0.11591612, ..., -0.03571848,\n",
       "          0.29090816,  0.3001495 ],\n",
       "        ...,\n",
       "        [-0.32230937,  0.11823259, -0.1158085 , ..., -0.11693042,\n",
       "          0.4659041 ,  0.42664543],\n",
       "        [-0.14730321,  0.2599754 ,  0.07127182, ..., -0.1017898 ,\n",
       "          0.49224174,  0.21545163],\n",
       "        [-0.18950048,  0.2985352 ,  0.07189725, ..., -0.10148148,\n",
       "          0.4928359 ,  0.205013  ]], dtype=float32),\n",
       " array([[-0.19379735,  0.3241807 ,  0.05120043, ..., -0.11595505,\n",
       "          0.40455   ,  0.3576633 ],\n",
       "        [-0.17898993,  0.3024001 ,  0.06656276, ..., -0.12167791,\n",
       "          0.4182551 ,  0.20802559],\n",
       "        [-0.6241444 ,  0.20684087, -0.3482126 , ..., -0.06520346,\n",
       "          0.34960914,  0.35185793],\n",
       "        ...,\n",
       "        [-0.25356835,  0.31558084,  0.07409398, ..., -0.02426728,\n",
       "          0.50528383,  0.30878526],\n",
       "        [-0.3048167 ,  0.4040491 ,  0.10098491, ..., -0.14591546,\n",
       "          0.48456565,  0.18728878],\n",
       "        [-0.34333545,  0.28395605, -0.03306188, ...,  0.01279226,\n",
       "          0.418651  ,  0.29380485]], dtype=float32),\n",
       " array([[-0.3757334 ,  0.2972853 , -0.03247573, ..., -0.00765772,\n",
       "          0.45088348,  0.33046833],\n",
       "        [-0.18082333,  0.36368948,  0.04526054, ..., -0.09930187,\n",
       "          0.43043515,  0.16696422],\n",
       "        [-0.26212275,  0.2679469 , -0.04928475, ..., -0.10231078,\n",
       "          0.44124806,  0.29987514],\n",
       "        ...,\n",
       "        [-0.422438  ,  0.09373148, -0.18871446, ..., -0.08037417,\n",
       "          0.38984624,  0.47406286],\n",
       "        [-0.31569782,  0.37349254,  0.1534245 , ..., -0.0779395 ,\n",
       "          0.32045442,  0.28787816],\n",
       "        [-0.23560996,  0.3444898 ,  0.00947151, ..., -0.03398047,\n",
       "          0.4548906 ,  0.26574022]], dtype=float32),\n",
       " array([[-2.0082359e-01,  3.7449384e-01,  7.7278838e-03, ...,\n",
       "         -1.1639126e-02,  4.6552902e-01,  2.4728064e-01],\n",
       "        [-2.2688490e-01,  3.8291669e-01,  3.8369812e-02, ...,\n",
       "         -1.5821190e-01,  4.2120928e-01,  3.4022671e-01],\n",
       "        [-2.4990363e-01,  4.9802479e-01, -3.4159794e-04, ...,\n",
       "         -9.2649601e-02,  4.5331293e-01,  2.9487589e-01],\n",
       "        ...,\n",
       "        [-3.7998906e-01,  1.5127918e-01, -5.2251432e-02, ...,\n",
       "         -2.6946740e-02,  4.0094700e-01,  3.0762997e-01],\n",
       "        [-2.1544066e-01,  2.7664915e-01,  3.1076308e-02, ...,\n",
       "         -1.4931889e-01,  4.0164778e-01,  3.1071621e-01],\n",
       "        [-2.9178023e-01,  4.7432476e-01, -1.3107825e-02, ...,\n",
       "         -2.9175533e-02,  3.8004261e-01,  3.4181800e-01]], dtype=float32)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebc33e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 768)\n"
     ]
    }
   ],
   "source": [
    "vectors = np.concatenate(embeddings)\n",
    "print(vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2408b33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = TruncatedSVD(n_components=100, random_state=0).fit_transform(vectors) # оставляем n главных компонент\n",
    "bert_vectors_redused  = pd.DataFrame(data['pn_lot_id']).join(pd.DataFrame(X_reduced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9055a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_lot_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7031618</td>\n",
       "      <td>13.501331</td>\n",
       "      <td>3.237092</td>\n",
       "      <td>0.807673</td>\n",
       "      <td>0.404966</td>\n",
       "      <td>-0.608116</td>\n",
       "      <td>0.231575</td>\n",
       "      <td>0.400840</td>\n",
       "      <td>0.482247</td>\n",
       "      <td>-0.176830</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.211987</td>\n",
       "      <td>0.090788</td>\n",
       "      <td>-0.105622</td>\n",
       "      <td>0.064085</td>\n",
       "      <td>-0.020659</td>\n",
       "      <td>0.105589</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>0.014205</td>\n",
       "      <td>-0.241538</td>\n",
       "      <td>-0.019701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7808247</td>\n",
       "      <td>13.664414</td>\n",
       "      <td>-1.028028</td>\n",
       "      <td>-0.967501</td>\n",
       "      <td>-0.708337</td>\n",
       "      <td>0.151037</td>\n",
       "      <td>0.106892</td>\n",
       "      <td>0.307951</td>\n",
       "      <td>-0.008613</td>\n",
       "      <td>-0.559414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072642</td>\n",
       "      <td>-0.200774</td>\n",
       "      <td>-0.179768</td>\n",
       "      <td>0.009964</td>\n",
       "      <td>-0.066842</td>\n",
       "      <td>-0.054728</td>\n",
       "      <td>-0.063379</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.037718</td>\n",
       "      <td>0.016285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7009496</td>\n",
       "      <td>13.553486</td>\n",
       "      <td>0.633898</td>\n",
       "      <td>-1.478396</td>\n",
       "      <td>-1.369439</td>\n",
       "      <td>0.757321</td>\n",
       "      <td>0.090601</td>\n",
       "      <td>0.221957</td>\n",
       "      <td>-0.206632</td>\n",
       "      <td>-0.395499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038435</td>\n",
       "      <td>0.022619</td>\n",
       "      <td>-0.127503</td>\n",
       "      <td>-0.078644</td>\n",
       "      <td>-0.020889</td>\n",
       "      <td>0.016643</td>\n",
       "      <td>-0.000573</td>\n",
       "      <td>-0.070886</td>\n",
       "      <td>0.052449</td>\n",
       "      <td>-0.052902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5938735</td>\n",
       "      <td>13.667197</td>\n",
       "      <td>1.453499</td>\n",
       "      <td>-0.643730</td>\n",
       "      <td>-1.013408</td>\n",
       "      <td>-0.046867</td>\n",
       "      <td>0.220003</td>\n",
       "      <td>0.138429</td>\n",
       "      <td>-0.544248</td>\n",
       "      <td>0.108580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081264</td>\n",
       "      <td>0.110336</td>\n",
       "      <td>0.037457</td>\n",
       "      <td>0.030405</td>\n",
       "      <td>-0.092684</td>\n",
       "      <td>0.045929</td>\n",
       "      <td>0.023358</td>\n",
       "      <td>0.021979</td>\n",
       "      <td>0.014179</td>\n",
       "      <td>0.095570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9327348</td>\n",
       "      <td>13.549007</td>\n",
       "      <td>-0.552627</td>\n",
       "      <td>-0.998366</td>\n",
       "      <td>0.032463</td>\n",
       "      <td>-0.305187</td>\n",
       "      <td>-0.602238</td>\n",
       "      <td>-0.100203</td>\n",
       "      <td>0.113755</td>\n",
       "      <td>-0.626121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005484</td>\n",
       "      <td>-0.008763</td>\n",
       "      <td>-0.079150</td>\n",
       "      <td>-0.048439</td>\n",
       "      <td>-0.016995</td>\n",
       "      <td>-0.041554</td>\n",
       "      <td>-0.128636</td>\n",
       "      <td>0.074861</td>\n",
       "      <td>-0.096709</td>\n",
       "      <td>0.057576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>8691563</td>\n",
       "      <td>13.832704</td>\n",
       "      <td>-0.307220</td>\n",
       "      <td>0.282596</td>\n",
       "      <td>-0.347251</td>\n",
       "      <td>0.236381</td>\n",
       "      <td>-0.268431</td>\n",
       "      <td>0.173621</td>\n",
       "      <td>-0.141698</td>\n",
       "      <td>0.246494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091687</td>\n",
       "      <td>0.010458</td>\n",
       "      <td>-0.050586</td>\n",
       "      <td>-0.063858</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>0.052563</td>\n",
       "      <td>-0.093054</td>\n",
       "      <td>-0.030072</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.074759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1951794</td>\n",
       "      <td>13.724087</td>\n",
       "      <td>-0.238426</td>\n",
       "      <td>-0.147065</td>\n",
       "      <td>-0.403062</td>\n",
       "      <td>-0.012487</td>\n",
       "      <td>0.430822</td>\n",
       "      <td>0.930970</td>\n",
       "      <td>0.031606</td>\n",
       "      <td>-0.273080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.002463</td>\n",
       "      <td>0.102267</td>\n",
       "      <td>0.055150</td>\n",
       "      <td>0.067703</td>\n",
       "      <td>0.046478</td>\n",
       "      <td>0.102742</td>\n",
       "      <td>0.083731</td>\n",
       "      <td>0.021148</td>\n",
       "      <td>0.157411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>3464251</td>\n",
       "      <td>13.824816</td>\n",
       "      <td>0.430473</td>\n",
       "      <td>-0.131659</td>\n",
       "      <td>0.130567</td>\n",
       "      <td>0.206427</td>\n",
       "      <td>0.280987</td>\n",
       "      <td>0.936840</td>\n",
       "      <td>-0.142142</td>\n",
       "      <td>0.022244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008341</td>\n",
       "      <td>-0.148073</td>\n",
       "      <td>0.043334</td>\n",
       "      <td>-0.042757</td>\n",
       "      <td>0.011266</td>\n",
       "      <td>0.070051</td>\n",
       "      <td>0.022419</td>\n",
       "      <td>0.070192</td>\n",
       "      <td>0.049736</td>\n",
       "      <td>-0.012234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>4093085</td>\n",
       "      <td>13.370934</td>\n",
       "      <td>-1.619873</td>\n",
       "      <td>-0.727181</td>\n",
       "      <td>-0.110802</td>\n",
       "      <td>0.524483</td>\n",
       "      <td>0.256816</td>\n",
       "      <td>0.862570</td>\n",
       "      <td>-0.115578</td>\n",
       "      <td>-0.375329</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179954</td>\n",
       "      <td>-0.036437</td>\n",
       "      <td>0.056522</td>\n",
       "      <td>0.111130</td>\n",
       "      <td>0.068333</td>\n",
       "      <td>0.024813</td>\n",
       "      <td>0.029127</td>\n",
       "      <td>0.005879</td>\n",
       "      <td>0.034918</td>\n",
       "      <td>0.054619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>3784645</td>\n",
       "      <td>14.005792</td>\n",
       "      <td>-0.619215</td>\n",
       "      <td>-0.004461</td>\n",
       "      <td>-1.641276</td>\n",
       "      <td>-0.084584</td>\n",
       "      <td>0.447106</td>\n",
       "      <td>-0.068980</td>\n",
       "      <td>0.125715</td>\n",
       "      <td>-0.027562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080586</td>\n",
       "      <td>0.104791</td>\n",
       "      <td>0.007827</td>\n",
       "      <td>0.062358</td>\n",
       "      <td>-0.063289</td>\n",
       "      <td>-0.080759</td>\n",
       "      <td>-0.031765</td>\n",
       "      <td>0.034131</td>\n",
       "      <td>0.069210</td>\n",
       "      <td>0.029948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pn_lot_id          0         1         2         3         4         5  \\\n",
       "0      7031618  13.501331  3.237092  0.807673  0.404966 -0.608116  0.231575   \n",
       "1      7808247  13.664414 -1.028028 -0.967501 -0.708337  0.151037  0.106892   \n",
       "2      7009496  13.553486  0.633898 -1.478396 -1.369439  0.757321  0.090601   \n",
       "3      5938735  13.667197  1.453499 -0.643730 -1.013408 -0.046867  0.220003   \n",
       "4      9327348  13.549007 -0.552627 -0.998366  0.032463 -0.305187 -0.602238   \n",
       "..         ...        ...       ...       ...       ...       ...       ...   \n",
       "995    8691563  13.832704 -0.307220  0.282596 -0.347251  0.236381 -0.268431   \n",
       "996    1951794  13.724087 -0.238426 -0.147065 -0.403062 -0.012487  0.430822   \n",
       "997    3464251  13.824816  0.430473 -0.131659  0.130567  0.206427  0.280987   \n",
       "998    4093085  13.370934 -1.619873 -0.727181 -0.110802  0.524483  0.256816   \n",
       "999    3784645  14.005792 -0.619215 -0.004461 -1.641276 -0.084584  0.447106   \n",
       "\n",
       "            6         7         8  ...        90        91        92  \\\n",
       "0    0.400840  0.482247 -0.176830  ... -0.211987  0.090788 -0.105622   \n",
       "1    0.307951 -0.008613 -0.559414  ...  0.072642 -0.200774 -0.179768   \n",
       "2    0.221957 -0.206632 -0.395499  ...  0.038435  0.022619 -0.127503   \n",
       "3    0.138429 -0.544248  0.108580  ...  0.081264  0.110336  0.037457   \n",
       "4   -0.100203  0.113755 -0.626121  ...  0.005484 -0.008763 -0.079150   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "995  0.173621 -0.141698  0.246494  ...  0.091687  0.010458 -0.050586   \n",
       "996  0.930970  0.031606 -0.273080  ...  0.000838  0.002463  0.102267   \n",
       "997  0.936840 -0.142142  0.022244  ...  0.008341 -0.148073  0.043334   \n",
       "998  0.862570 -0.115578 -0.375329  ... -0.179954 -0.036437  0.056522   \n",
       "999 -0.068980  0.125715 -0.027562  ...  0.080586  0.104791  0.007827   \n",
       "\n",
       "           93        94        95        96        97        98        99  \n",
       "0    0.064085 -0.020659  0.105589  0.019773  0.014205 -0.241538 -0.019701  \n",
       "1    0.009964 -0.066842 -0.054728 -0.063379 -0.000343 -0.037718  0.016285  \n",
       "2   -0.078644 -0.020889  0.016643 -0.000573 -0.070886  0.052449 -0.052902  \n",
       "3    0.030405 -0.092684  0.045929  0.023358  0.021979  0.014179  0.095570  \n",
       "4   -0.048439 -0.016995 -0.041554 -0.128636  0.074861 -0.096709  0.057576  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "995 -0.063858  0.036700  0.052563 -0.093054 -0.030072  0.000586  0.074759  \n",
       "996  0.055150  0.067703  0.046478  0.102742  0.083731  0.021148  0.157411  \n",
       "997 -0.042757  0.011266  0.070051  0.022419  0.070192  0.049736 -0.012234  \n",
       "998  0.111130  0.068333  0.024813  0.029127  0.005879  0.034918  0.054619  \n",
       "999  0.062358 -0.063289 -0.080759 -0.031765  0.034131  0.069210  0.029948  \n",
       "\n",
       "[1000 rows x 101 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_vectors_redused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd1f335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_vectors_redused.to_csv('../data/intermid/bert_vectors_redused.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bfb2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c147b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674d3a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc4ba85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5b0821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe7b835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbb010e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
